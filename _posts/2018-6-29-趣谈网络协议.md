---
layout: post
title: "趣谈网络协议"
description: "网络"
category: NetWork
tags: [Life]
---

{% include JB/setup %}


--------------------------


# 趣谈网络协议
**应用层**: `DNS`, `Http`, `Https` 所在的层为应用层.

**传输层**: 应用层封装成包之后会交给传输层（通过`Socket`编程来实现), `传输层`有两种协议：
* 无连接的`UDP`协议
* 面向连接的`TCP`协议
    * `TCP` 协议里有两个端口:
        * 浏览器监听的端口
        * 服务器监听的端口

> 操作系统往往通过端口来判断得到的包应该给哪个进程。

**网络层**: 网络层的协议是IP协议, 会有源`IP`地址和目标`IP`地址。
> 操作系统启动的时候会被 `DHCP` 协议配置`IP`地址, 以及默认网关的IP地址*(192.168.1.1)*.

**MAC层**: 操作系统通过 `ARP` 协议将`IP`地址发送给网关, 将 `IP`包交给下一层 `Mac层`.

* 网关往往是一个路由器, 路由器上维护一张路由表, 路由表由    相邻的路由器通过路由协议得到(常用的有 `OSPF` 和 `BGP`). 最后一个路由器知道这个网络包要去的地方，目标服务器会回复一个 `Mac地址`,  通过这个 `Mac地址`就可以找到目标服务器.

* 目标服务器发现 `Mac地址` 对上， 取下 `Mac头` 发送给操作系统`网络层`, 发现 `IP` 也对上, 取下`IP头`交给`传输层(TCP层)`，传输层对于收到的每个包，都会回复一个包说明收到。如果过一段时间还没到，发送端的`TCP层`会重新发送这个包。

* 当网络包平安到达 `TCP层` 之后, `TCP头`中有目标端口号. 通过 `RPC调用`(`RPC`框架有很多种，有基于`HTTP协议`的放在`HTTP`报文里的，有直接封装在`TCP`报文里的) 来告诉监听这个端口的服务器进程。

## ifconfig 命令
`Windows`上通过`ipconfig`, `Linux`上通过`ifconfig`命令或者`ip addr`命令 `来查看`IP`地址.
> `IP`地址是一个网卡在网络世界的通讯地址，相当于我们现实世界的门牌号。

## 无类型域间选路(CIDR)
将`32`位的`IP`地址分为网络考和主机好两部分。类似于 `10.100.122.2/24`, 前`24`位表示网络号，后`8`位表示主机号.

## 公有IP地址和私有IP地址

![Ip分类]( http://7xpgi9.com1.z0.glb.clouddn.com/IPRange.png "IP分类")

> 公有`IP`地址有个组织统一分配。`192.168.0.x`是最常用的私有`IP`地址.`192.168.0.1`往往就是私有网络的出口地址，例如：家里的电脑连接 `Wi-Fi`, `Wi-Fi` 路由器的地址就是 `192.168.0.1`. `192.168.0.255` 是广播地址, 一旦发送这个地址， 整个`192.168.0`网络里的所有机器都能收到。

## ICMP与ping
`ping` 是基于`ICMP`(`Internet Control Message Protocol`, 互联网控制报文协议)协议工作的. `ICMP` 报文封装在 `IP` 包里面, 有很多的类型，不同类型有不同的代码。最常用的类型是主动请求为`8`, 主动请求的应答为`0`. 常用的`ping`就是查询报文，是一种主动请求，并且获得主动应答的`ICMP`协议.

对`ping`的主动请求，进行抓包称为 `ICMP ECHO REQUEST`.同理主动请求的回复，称为`ICMP ECHO REPLY`.比起原生的`ICMP`, 这里多了两个字段:
* 标识符
* 序号

### ICMP差错报文类型
* 终点不可达`3`, 具体的原因在代码中的标示
    * 网络不可达代码为`0`
    * 主机不可达代码为`1`
    * 协议不可达代码为`2`
    * 端口不可达代码为`3`
    * 需要进行分片但设置了不分片位代码为`4`
* 源抑制`4`
* 超时`11`
* 重定向`5`

### ping: 查询报文类型的使用
`主机A` 的`IP`地址是`192.168.1.1`, `主机B`的`IP`地址是`192.168.1.2`, 在同一子网， `主机A` 运行 `ping 192.168.1.2` 发生了啥？

> 源主机首先会构建一个`ICMP`请求数据包，`ICMP`数据包包含多个字段。最重要的以下两个：
* 类型字段: 对于请求数据包而言该字段为`8`
* 顺序号: 主要用于区分连续`ping`时发出的多个数据包,每发出一个请求数据包，顺序号会自动`+1`.

> 为了能计算往返时间`RTT`, 会在报文的数据部分插入发送时间。然后，由`ICMP`协议将数据包连同地址`192.168.1.2`一同交给`IP层`。`IP层`以`192.168.1.2`作为目的地址，本机`IP地址`作为源地址，加上一些其他控制信息，构建一个`IP数据包`。

### MAC头和IP头的细节
`MAC头`: 里先是`目标MAC地址`，然后是`源MAC地址`和一个协议类型。用来说明里面是`IP`协议。
`IP头`: 里面的版本号， 目前主流的是`IPv4`, 服务类型`TOS`,`TTL`和`8`标识协议.

任何一台机器上，当要访问另一个`IP地址`的时候，都会先判断，这个`目标IP地址`和当前机器的`IP地址`是否在同一网段，需要使用`CIDR`和子网掩码。
* 同一网段：直接将源地址和目标地址放入`IP头`中，然后通过`ARP`获得`MAC地址`，将`源MAC`和`目的MAC`放入`MAC头`中发出去。
* 不同网段: 需要发往默认网关`Gateway`, `Gateway`地址一定和`源IP地址`在同一网段。网关往往是一个路由器，是一个三层转发设备。但是把网关叫做路由器是不完全准确的 `路由器是一台设备，它有五个网口或网卡，相当于有五只手，分别连着五个局域网。每只手的IP地址都和局域网的IP地址在相同的网段，每只手都是它握住哪个局域网的网关`

## UDP 协议
`TCP`是面向连接的， `UDP`是面向无连接的。在互通之前，面向连接的协议会先建立连接，例如：`TCP`会三次握手，而`UDP`不会。

**所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。**
* **`TCP`提供可靠交付**。通过`TCP`连接传输的数据，无差错，不丢失，不重复，并且按序到达。 **`UDP`继承了`IP包`的特性，不保证不丢失，不保证按顺序到达。**
* **`TCP`是面向字节流的**。发送的时候发的是一个流，没头没尾。`IP包`不是一个流，而是一个个`IP包`。之所以变成流，是`TCP`自己状态维护做的事情。**`UDP`继承了`IP`的特性，基于数据报的, 一个个的发，一个个的收。**
* **`TCP`可以有拥塞控制的**。它意识到包丢弃了或者网络环境不好，会根据清空调整自己的行为，看看是不是发快了， 要不要发慢点。 **UDP就不会，应用让我发，我就发。**
* **`TCP`其实是一个有状态服务**， **而`UDP`则是无状态服务**

### UDP包头
当我们发送的`UDP`包到达目标机器后，发现`MAC地址`匹配，于是取下来，将剩下的包传给处理`IP层`的代码。把`IP头`取消来，里面有个`8位`协议，会标示出数据到底是`TCP`还是`UDP`。

无论是`TCP`传数据还是`UDP`传数据，都要监听一个端口。`TCP` 还是 `UDP` 包头里有个端口号， 根据端口号，将数据交给相应的应用程序。

### UDP三大特点 
* **沟通简单**：不需要大量的数据结构，处理逻辑，包头字段。
* **轻信他人**：不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，它也可以传给任何人数据，甚至可以同时传给多人数据。
* **做事不懂权变**：不会根据网络的情况进行发包的拥塞控制，无论网络丢包成啥样，还是该怎么发就怎么发。

### UDP三大使用场景 
* **需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用**
* **不需要一对一沟通，建立连接，而是可以广播的应用**
* **需要处理速度快，时延低， 可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前**

### UDP的五个例子
* **网页或者`App`的访问**: `QUIC`(Quick UDP Internet Connections，快速`UDP`互联网连接啊)是`Google`提出的一种基于`UDP`改进的通信协议，目的是降低网络通信延迟，提供更好的用户互动体验。`QUIC`在应用层上，会自己实现快速连接建立，减少重传时延，自适应拥塞控制。
* **流媒体协议**: 直播协议多使用`RTMP`(也是基于`TCP`的), 由于`TCP`的限制，很多直播应用都基于`UDP`实现自己的视频传输协议。
* **实时游戏**: 要求较为严格，采用自定义的可靠`UDP`协议，自定义重传策略， 能够把丢包产生的延迟降到最低，尽量减少网路问题对游戏性造成的影响。
* **IoT物联网**：一方面物联网领域终端资源少，很可能只是个内存非常小的嵌入式系统，而维护`TCP协议`代价太大；另一方面，物联网对实时性要求也很高，`Google`旗下的`Nest`建立`Thread Group`，推出了物联网通信协议 `Thread` , 就是基于`UDP协议的`
* **移动通行领域**: 在`4G`网络里，移动流量上网的数据面对的协议`GTP-U`是基于`UDP`的。因为移动网络协议比较复杂，而`GTP协议`本身就包含复杂的手机上线下线的通信协议。如果基于`TCP`, `TCP`的机制就显得非常多余。

## TCP 协议
### TCP包头格式 
* **源端口号**和**目标端口号**是不可少的，这一点和`UDP`一样。如果没有这两个端口号，数据就不知道应该发给哪个应用。
* **包的序列号**为了解决乱序的问题。
* **确认序号**发出去的包应该有确认，如果没有收到就应该重新发送，直到送达。这个可以解决不丢包的问题。
> `TCP`是可靠的协议，对于`TCP`来讲，`IP层`丢不丢包我管不着，我自己会通过不断重传保证可靠性。

* **状态位**: `SYN`是发起一个连接，`ACK`是回复, `RST`是重新连接, `FIN`是结束连接。`TCP`是面向连接的，双方要维护连接的状态，这些带状态位的包发送，会引起双方的状态变更。
* **窗口大小**: `TCP`要做**流量控制**，通信双方各申明一个窗口，标示自己当前的处理能力，别发送太快，也别发送太慢。
* **拥塞控制**：对于真正的通路堵不堵车，它无能为力，唯一能做的就是控制自己(控制发送的速度)

`TCP`协议需要重点关注以下几个问题：
 * 顺序问题，稳重不乱
 * 丢包问题，承诺靠谱
 * 连接维护，有始有终
 * 流量控制，把握分寸
 * 拥塞控制，知进退
 
### TCP三次握手
我们假设通路非常不靠谱，`A`要发起一个连接，当发了第一个请求了无音讯的时候，会有很多可能性，比如**第一个请求包丢了**, **超时了**还是**`B`没有响应，不想和我连接**。

`A`不能确认结果，于是再发。终于，又一个请求包到了`B`, 但是请求包到了`B`这个事情，`A`是不知道的，`A`还有可能再发。

`B`收到请求包，就知道`A`的存在，并且知道`A`要和它建立连接。如果`B`不乐意建立连接，则`A`会重试一段时间后放弃，连接建立失败，没有问题；如果`B`乐意建立连接，则会发送应答包给`A`。

对于`B`来说，这个应答包也是不知道能不能到达`A`。这个时候`B`自然不能认为连接建立好了，因为应答包仍然会丢，会绕弯路，或者`A`已经挂了。这个时候`B`还碰到一个诡异的现象，`A`和`B`原来建立连接，做了简单通信后，结束连接。`A`建立连接时，请求包重复发了几次，有的请求包绕了一大圈又回来，`B`会认为这是一个正常的请求，因此建立连接，可以想象这个连接不会进行下去，也没有终止的时候。

`B`发送的应答可能会发送多次，但只要一次到达`A`, `A`就认为连接已经建立，因为对于`A` 来说，他的消息有去有回，`A`会给`B`应答的应答，只有当`B`等到这个消息才会建立连接。
> 三次握手除了双方建立连接外，主要为了沟通**`TCP包`的序号问题**。每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个`32`位的计数器，每`4ms`加一。

### TCP 四次挥手
`A`开始说"不玩了"，`B`说"知道了"。这个是没有什么问题的，因为在此之前，双方还处于合作状态，如果`A`说"不玩了"，没有收到回复，就会重新发送。但是这个会和结束之后，就可能有异常情况：
* `A`说完"不玩了"之后，直接跑路，就会有问题，`B`还没有发起结束，也得不到回答，`B`就不知道怎么办
* `A`说完"不玩了"，`B`直接跑路，也是有问题的，因为`A`不知道`B`是还是事情要处理，还是过一会儿会发送结束。

> `TCP` 专门设计几种状态来处理这些问题:
* 断开的时候, 当`A`说"不玩了"，就进入`FIN_WAIT_1`的状态，`B`收到`A不玩了`的消息后，发送知道了就进入`CLOSE_WAIT`的状态
* `A`收到`B说知道了`，就进入`FIN_WAIT_2`状态，如果这个时候`B`直接跑路，则`A`将永远在这个状态。`TCP`协议里没有对这个状态的处理，但是`Linux`有，可以调整`tcp_fin_timeout`这个参数， 设置一个超时时间。
* `B`没有跑路，发送了`B也不玩了`的请求到达`A`时，`A`发送"知道B也不玩了"的`ACK`后，从`FIN_WAIT_2`状态结束，按说`A`可以跑路了，但是这个最后的`ACK`万一`B`收不到呢? 则`B`会重新发一个`B不玩了`，这个时候`A`已经跑路了的话，`B`就再也收不到`ACK`了， 因而`TCP协议`要求`A`最后等待一段时间`TIME_WAIT`, 这个时间要足够长，长到如果`B`没有收到`ACK`的话，"B 说不玩了"会重发，`A`会重新发一个`ACK`并且足够时间到达`B`。
* `A` 直接跑路还有一个问题，`A`的端口直接空出来了，但是`B`不知道，`B`发送过来的恶很多包很可能还在路上，如果`A`的端口被一个新的应用占用，这个新的应用就会收到上个连接中`B`发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而需要等足够长的时间，等到原来`B`发送的所有包都死翘翘，再空出端口来。等待时间设为`2MSL`(MSL是Maximum Segment Lifetime, 报文最大生存时间)
* 还有个异常就是`B`超过`2MSL`后，依然没有收到它发的`FIN`的`ACK`, 按照`TCP`的原理，`B`当然会重发`FIN`, 这个时候`A`再收到这个包之后，`A`就直接发送`RST`, `B`就知道`A`早跑了。

### 如何实现靠谱的协议
`TCP协议`为了保证顺序性，每一个包都有一个`ID`。在建立连接的时候，会商定起始的`ID`是什么，然后按照`ID`一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个个来的，而是会应答某个之前的`ID`, 表示都收到了, 这种模式称为**累计确认或累计应答**(`cumulative acknowledgment`)。为了记录所有发送和接收的包，`TCP`也需要发送和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的`ID`一个个排列，根据处理情况分成`4`个部分：
* 发送并且已经确认的。这部分表示处理完的，应该划掉。
* 发送并尚未确认的。还没有处理完的，需要等待处理完回复之后，才能划掉。
* 没有发送，但是已经等待发送，这部分还没有交代给下属，但是马上要交代的。
* 没有发送，并且暂时也不会发送。这部分表示还没有交代下属，而且暂时也不会交代给下属。
> 第`3`点和第`4`点做区分是为了**流量控制，把握分寸**。在`TCP`里，接收端会给发送端报一个窗口大小(`Advertised Window`), 这个窗口的大小应该等于第`2`点和第`3`点的总和，超过这个窗口，接收端处理不过来就不能发送。

于是发送端需要保持下面的数据结构:
* `LastByteAcked`: 第`1`点和第`2`点的分界线
* `LastByteSent`: 第`2`点和第`3`点的分界线
* `LastByteSend + AdvertisedWindow`: 第`3`点和第`4`点的分界线

对于接收端来说，它的缓存里记录的内容要简单一些：
* **接收并确认过的**: 就是交代给我，并且我做完的。
* **还没接收,但是马上就能接收的**: 就是我自己能够接收的最大工作量
* **还没接收，也没法接收的**: 超出工作量的部分，实在做不完。

> 对应的数据结构就是:
* `MaxRcvBuffer`: 最大缓存的量
* `LastByteRead`: 之后是已经接收了，但还没有被应用层读取的。
* `NextByteExpected`: 第`1`部分和第`2`部分的分界线。

## Socket套接字
`Socket`编程进行端到端通信，往往意识不到中间经过多少局域网，多少路由器，因而能够设置的参数，也只能是端到端协议之上网络层和传输层。
> 在网络层，`Socket`函数需要指定到底是`IPv4`还是`IPv6`, 分别对应设置为`AF_INET`和`AF_INET6`。另外，还要指定到底是`TCP`(**基于数据流*，设置为`SOCK_STREAM`)还是`UDP`(**基于数据报**,设置为`SOCK_DGRAM`)。

### 基于TCP协议的Socket程序函数调用过程
两端创建`Socket`之后, `TCP`服务端先监听一个端口，一般先调用`bind函数`, 给这个`Socket`赋一个`IP`和`端口`。原因如下:
* `IP`: 一台机器可能会有多个网卡，也就有多个`IP`地址,可以选择监听所有的网卡，也可以选择监听一个，只有发给这个网卡的包才会给你。
* `端口`: 一个网络包来的时候，内核要通过`TCP头`里的这个端口，来找到你这个应用程序，把包给你。

当服务器有`IP`和`端口号`, 就可以调用`listen`函数进行监听。在`TCP`的状态图里，有个`listen`状态，当调用这个函数之后， 服务器就进入这个状态， 客户端就可以发起连接。

内核中为每个`Socket`维护两个队列：
* 已经建立连接的队列， 这时连接三次握手已经完毕，处于`established`状态
* 还没有完全建立连接的队列，这时三次握手还没有完成，处于`syn_rcvd`状态

接下来，服务端调用`accept`函数，拿出一个已完成的连接进行处理，如还没完成就要等着。在服务端等待的时候，客户端可以通过`connect`函数发起连接，先在参数中指明要连接的`IP地址`和`端口号`， 然后开始发起三次握手，内核会给客户端分配一个临时的端口。一旦握手成功，服务端的`accept`就会返回另一个`Socket`。监听的`Socket`和真正用来传数据的`Socket`是两个，一个叫做**监听Socket**, 一个叫做**已连接Socket**。连接建立成功之后，双方开始通过`read`和`write`函数来读写数据，就像往一个文件流里写东西一样。

![Socket](http://7xpgi9.com1.z0.glb.clouddn.com/socket1.JPG "Socket")

在内核中`Socket`是一个文件，对应就有文件描述符。每个进程都有一个数据结构`task_struct`，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是个整数，是这个数组的下标。这个数组中的内容是一个指针，指向内核中所有打开的文件列表。既然是一个文件，就会有一个`inode`, 只不过`Socket`对应的`inode`不像真正的文件系统一样，保存在硬盘上，而是在内存中。这个`inode`指向`Socket`在内核中的`Socket`的结构。

这个结构里，主要是两个队列，1.**发送队列** 2.**接收队列**。在这两个队列里保存的是一个缓存`sk_buff`。这个缓存里能够看到完整的包结构。

### 基于UDP协议的Socket程序函数调用过程
`UDP`是没有连接的，不需要三次握手，也就不需要调用`listen`和`connect`, 但`UDP`交互仍需要`IP`和`端口号`就需要`bind`。`UDP`是没有维护连接状态的，因而不需要每对连接建立一组`Socket`, 而是只要有一个`Socket`就能和多个客户端通信。也正是因为没有连接状态，每次通信时，都调用`sendto`和`recvfrom`, 都可以传入`IP地址`和端口。

### 服务器如何连接更多项目
**最大连接数**, 系统会用一个四元祖来标识一个`TCP`连接。
> {本机IP, 本机端口，对端IP, 对端端口}

服务器通常固定在某个本地端口上监听，等待客户端的连接请求。因此，服务端`TCP`连接四元祖中只有`对端IP`（客户端`IP`）和 `对端端口`(客户端端口)是可变的。因此:
> 最大`TCP`连接数 = 客户端`IP`数 x 客户端端口数

> 对于`IPv4`，客户端`IP`数最多为`2^32`, 客户端端口数最多为`2^16`, 也就是服务端单机最大`TCP`连接数，约为 `2^48`。

当然，服务端最大并发`TCP`连接数远不能达到理论上限。首先主要是**文件描述符限制**, 按照上面的原理，`Socket`都是文件，所以首先要通过`ulimit`配置文件描述符数目；另一个限制是**内存**, 按照上面的数据结构，每个`TCP`连接都要占用一定内存，操作系统内存是有限的。

可以通过以下方式来降低每个项目消耗的资源数目：

![方式一](http://7xpgi9.com1.z0.glb.clouddn.com/socket2.JPG "方式一")

* **将项目外包给其他公司(多进程方式)**: 一旦建立一个连接，就会有个已连接`Socket`, 这时可以创建一个子进程，然后将基于已连接`Socket`的交互交给这个新的子进程来做。在`Linux`下，创建子进程使用`fork`函数（在父进程的基础上完全拷贝一个子进程）。在`Linux`内核中，会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到哪行程序的进程。显然, 复制的时候调用`fork`, 复制完毕之后，父进程和子进程都会记录当前刚刚执行完`fork`。这两个进程刚复制完的时候，几乎一摸一样，只是根据`fork`的返回值来区分到底是父进程(返回其他整数)，还是子进程(返回`0`)。因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为`accept`创建的已连接`Socket`也是一个文件描述符，同样会被子进程获得。 接下来, 子进程可以通过这个已连接`Socket`和客户端进行互通了，当通信完毕之后，就可以退出进程。（`fork`时返回整数就是父进程，这个整数就是子进程的`ID`, 父进程可通过这个`ID`查看子进程是否完成项目，是否需要退出）

![方式二](http://7xpgi9.com1.z0.glb.clouddn.com/socket3.JPG "方式二")

* **将项目转包给独立的项目组(多线程方式)**: 相比`进程`来说，创建`线程`就相当于在同一个公司成立项目组。一个项目做完了，那这个项目组就可以解散，组成另外的项目组，办公家具都可公用。在`Linux`下，通过`pthread_create`创建一个线程，也是调用`do_fork`。 不同的是，虽然新的线程在`task`列表会新创建一项，但是很多资源，例如**文件描述符列表**，**进程空间**，还是共享的，只不过多了一个应用而已。新的线程也可以通过已连接`Socket`处理请求，从而达到并发处理的目的。

> 上面基于进程或线程模型，其实还是有问题的。新到来一个`TCP`连接，就需要分配一个进程或线程。一台机器无法创建很多进程或线程。有个`C10K`(**一台机器要维护`1万`个连接，就要创建`1万`个进程或线程，操作系统是无法承受的**)。

* **一个项目组支撑多个项目(IO多路复用，一个线程维护多个Socket)**: 由于`Socket`是文件描述符，因而某个线程盯的所有`Socket`,都放在一个文件描述符集合`fd_set`中，这就是**项目进度墙**，然后调用`select`函数来监听文件描述符集合是否有变化。一旦变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在`fd_set`对应的位都设为`1`，表示`Socket`可读可写，从而可以进行读写操作，然后调用`select`进行下一轮。

![方式四](http://7xpgi9.com1.z0.glb.clouddn.com/socket4.JPG "方式四")

* **一个项目组支撑多个项目(IO多路复用，从"派人盯着"到"有事通知")**: 上面`select`函数还是有问题，因为每次`Socket`所在地恶文件描述符集合中`Socket`发生变化时，都需要通过轮询的方式来查看进度，这大大影响了一个项目组能支撑的最大项目数量。因而使用`select`, 能够同时盯的项目数量由`FD_SETSIZE`限制。如果改成事件通知的方式，情况就会好很多，项目组不需要通过轮询挨个盯着这些项目，而是当项目进度发生变化时，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。能完成这件事的函数叫`epoll`, 它在内核中的实现不是通过轮询的方式，而是通过注册`callback函数`的方式，当某个文件描述符发送变化时，就会主动通知。如图所示，假设进程打开了`Socket` `m n x`等多个文件描述符，现在需要通过`epoll`来监听是否这些`Socket`都有事件发生。其中`epoll_create`创建一个`epoll对象`，也是一个文件，也对应一个文件描述符，同样对应着打开文件列表中的一项。在这项里有一个红黑树，在红黑树里，要保存这个`epoll`要监听所有`Socket`。当`epoll_ctl`添加一个`Socket`时，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的`Socket`事件列表中。到一个`Socket`来了一个事件时，可以从这个列表中得到`epoll对象`,并调用`callback`通知它。这种通知方式使得监听的`Socket`数据增加的时候，效率不会大幅度降低，能够同时监听的`Socket`的数目也非常多。上限为系统定义的，进程打开的最大文件描述符个数。因而，**epoll被称为解决`C10K`问题的利器**。

## HTTP协议
登陆 [www.163.com](http://www.163.com) 这个 `URL`(同一资源定位符), 浏览器会将 [www.163.com](http://www.163.com) 这个域名发送给 `DNS服务器`, 让他解析`IP地址`. `HTTP` 先通过三次握手建立 `TCP连接`. (目前使用的`HTTP协议`大部分都是`1.1`, 是默认开启 `Keep-Alive`, 建立的`TCP`连接，可以在多次请求中复用)。

`HTTP`的报文可以分为`3`大部分
* 请求行
请求行中`URL`就是[www.163.com](http://www.163.com)，版本为`HTTP 1.1`, **方法**有几种类型:
    * 访问网页来说，最常用的就是`GET`，服务器决定放回什么格式的内容(`JSON`字符串等)。
    * `POST` 需要主动告诉服务器一些信息。一般会放在正文里。正文可以用各种各样的格式。常见的格式也是`JSON`.
    * `PUT` 向指定资源位置上传最新内容. 但是，`HTTP`服务器往往不允许上传文件， 所以 `PUT` 和 `POST` 都变成要穿东西给服务器的方法。实际使用过程中， `POST` 往往用来创建一个资源，`PUT` 用来修改资源。
    * `DELETE` 用来删除资源。

* 首部
首部都是 `key` `value` 格式，通过冒号分隔。 里面保存一些非常重要的字段。例如:
    * `Accept-Charset` 表示客户端可以接收的字符集, 防止产生乱码。
    * `Content-Type` 表示正文的格式，我们使用 `POST` 请求， 如果正文是`JSON`这个值设置为`JSON`.
    * `Cache-control` 用来控制缓存
    * `If-Modified-Since`
* 正文实体

> `HTTP`请求发送: `HTTP协议` 是基于`TCP协议`的， 使用面向连接的方式发送请求， 通过 `stream` 二进制流的方式传给对方， 到了`TCP层`, 会把二进制流变成一个个报文段发送给服务器.

### HTTP返回的构建
`HTTP` 返回报文也有一定格式， 也是基于`HTTP 1.1`.
* 状态行
    * 状态码： 会反应`HTTP`请求的结果. `200`意味一切顺利; `404` 表示服务器无法响应这个请求。
    * 短语: 会大概说明一下原因。
* 首部
    * `Retry-After`表示告诉客户端应该在多长时间之后再尝试。`503`错误表示**服务器暂时不再和这个值配合使用**。
    * `Content-Type` 表示返回的是`HTML` 还是 `JSON`.

> `HTTP 1.1` 在应用层以纯文本的形式进行通信。 每次通信都要带完整的`HTTP头`, 不考虑`pipeline模式`的话， 每次的过程总是一来一回， 在**实时性**, **并发性**上都存在问题。 `HTTP 2.0` 会对 `HTTP头`进行一定的压缩， 将原来每次都要携带得的大量的 `key value` 在两端建立一个索引表, 对相同的头只发送索引表中的索引。

`Google` 的 `QUIC协议`, 从 `TCP` 切换到 `UDP`, 有如下几个特点:
* 自定义连接机制
> 不再以四元组(`源IP`,`源端口`,`目的IP`,`目的端口`)标识，而是以一个`64位`随机数作为`ID`来标识，而且`UDP`是无连接的，所以`IP`或`端口`变化时, 只要`ID`不变， 就不需要重新建立连接.

* 自定义重传机制
> `TCP` 为了保证可靠性，通过使用**序号**和**应答**机制类解决顺序和丢包问题。`QUIC`定义来一个`offset`的概念。`QUIC`是面向连接的，就像`TCP`一样是一个数据流, 发送的数据在这个数据流里有个偏移量`offset`, 可以通过 `offset` 查看数据发送到哪里， 只要`offset`包没有来就要重发。

* 无阻塞多路复用
> 有了自定义的连接和重传机制就可以解决`HTTP 2.0`的多路复用问题。

* 自定义流量控制
> `TCP`通过**滑动窗口协议**来实现流量控制。`QUIC`也通过`window_update`, 但是是适应自己的多路复用机制的， 不但在一个连接上控制窗口， 还在一个连接中的每个`steam`控制窗口。

## HTTPS协议
加密分为两种方式：
* **对称加密**
> 对称加密算法中，加密和解密使用的密钥是相同的。因此，堆成加密算法要保证安全性的话，密钥要做好保密。只能让使用的人知道，不能对外公开。                    

* **非对称加密**
> 加密使用的密钥和解密使用的密钥是不相同的。一把是作为公开的公钥，另一把是作为谁都不能给的私钥。公钥加密的信息，只能私钥才能解密。私钥加密的信息，只有公钥才能解密。客户端也需要有自己的公钥和私钥。

所以对称加密算法相比非堆成加密算法来说，效率高很多，性能也好，所以交互的场景下多用对称加密。

### 数字证书
不对称加密也会有同样的问题，何如将不对称加密的公钥给对方？一种是放在一个公网的地址上，让对方下载；另一种是在建立连接时传给对方。两种方法有相同的问题，作为一个普通的网民，怎么鉴别公钥是对的，例如，我自己搭建一个网站`cliu8site`可以通过以下命令先创建私钥：

```plain
openssl genrsa -out cliu8siteprivate.key 1024
```

然后再根据私钥创建对应的公钥。

```plain
openssl rsa -in cliu8siteprivate.key -pubout -outcliu8sitepublic.pem
```

这个时候就需要权威部门介入，就像每个人都可以打印自己的简历，说自己是谁，但有公安局盖章的，就只有户口本，才能证明你是你。这个由权威部门颁发的称为**证书(Certificate)**。

**证书(Certificate)**里应该有**公钥**, 还有证书的**所有者**,就像户口本上有你的姓名和身份证号，说明这个户口本是你的；另外还有证书的**发布机构**和证书的**有效期**。这个证书是怎么生成的呢? 会不会有人假冒权威机构颁发证书？就像有假身份证，假户口一样。生成证书需要发起一个证书请求，然后将这个请求发给一个权威机构去认证，这个权威机构我们称为**CA(`Certifcate Authority`)**, 证书请求可以通过命令生成：

```plain
openssl req -key cliu8siteprivate.key -new -out cliu8sitecertificate.req
```

将这个请求发给权威机构，权威机构会给这个证书盖章，我们称为**签名算法**. 只有使用 `CA`的私钥签名才能保证是真的权威机构的签名。签名算法大概的工作流程：对信息做一个`Hash`计算，得到一个`Hash`值，这个过程是不可逆的，再把信息发送出去时，把这个`Hash`值加密后，作为一个签名和信息一起发出去。权威机构给证书签名的命令如下:

```plain
openssl x509 -req -in cliu8sitecertificate.req -CA cacertificate.pem -CAkey \
caprivate.key -out cliu8sitecertificate.pem
```

这个命令会返回`Signature ok`, 而`cliu8sitecertificate.pem`就是签过名的证书。`CA`用自己的私钥给外卖网站的公钥签名，就相当于给外卖网站背书，形成外卖网站的证书。证书的内容：

```plain
openssl x509 -in cliu8sitecertificate.pem -noout -text
```

这里有个`Issuer`(证书是谁颁发的)；`Subject`(证书颁发给谁); `Validity`(证书期限)；`Public-key`(公钥内容);`Signature Algorithm`(签名算法)。这下你不会从外卖网站上得到公钥，而是得到一个证书，这个证书有个发布机构`CA`,你只要得到这个发布机构`CA`的公钥，去解密外卖网站证书的签名，如果解密成功，`Hash`也对上，就说明这个外卖网站的公钥没啥问题。

要想验证证书，需要`CA`的公钥，问题是，怎么确定`CA`的公钥是对的？所以，`CA`的公钥需要更牛的`CA`给它签名，然后形成`CA`的证书。要想知道某个`CA`的证书是否可靠，要看`CA`的上级证书是否可靠，要看`CA`的上级证书的公钥，能不能解开这个`CA`的签名，`CA`的公钥也需要更牛的`CA`给它签名，然后形成`CA`的证书，这样层层上去，直到全球皆知的几个著名大`CA`,称为`root CA`, 做最后的背书。通过这种 **层层授信背书**的方式，从而保证了非对称加密模式的正常运转。

除此之外，还有一种证书，称为**Self Signed Certificate**, 给人一种"我就是我，你爱信不信"。

### HTTPS的工作模式
我们知道，非对称加密在性能上不如对称加密，那是否能将两者结合？例如，公钥私钥主要用于传输对称加密的秘钥，而真正的双方大数据量的通信都是通过对称加密进行的。这就是`HTTPS`协议的总体思路:
![Https](http://7xpgi9.com1.z0.glb.clouddn.com/https1.JPG "Https")

当你登陆外卖网站时，由于是`HTTPS`,客户端会发送`Client Hello`消息到服务器，以明文传输`TLS`版本信息，加密套件候选列表，压缩算法候选列表等信息。另外，还会有一个随机数，在协商对称秘钥时使用。然后，外卖网站返回`Server Hello`消息告诉客户端，服务器选择使用的协议版本，加密套件，压缩算法等，还有一个随机数，用于后续的密钥协商。然后外卖网站会给一个服务端的证书说："Server Hello Done, 我这里就这些信息了"。

你当然不相信这个证书，于是从自己信任的`CA`仓库中，拿`CA`的证书里面的公钥去解密外卖网站的证书。如果能够成功，说明外卖网站是可信的。这个过程中，可能会不断往上追溯`CA`, `CA`的`CA`, `CA`的`CA`的`CA`,反正直到一个授信的`CA`。

证书验证完毕之后，觉得这个外卖网站可信，于是客户端计算产生随机数字`Pre-master`, 发送`Client Key Exchange`, 用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。

到目前为止，无论是客户端还是服务器，都有三个随机数，分别是：自己的，对端的，以及刚生成的`Pre-master`随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。有了对称密钥，客户端就可以说："`Change Clipher Spec`", 咱们以后都采用协商的通信密钥和加密算法进行加密通信。然后发送一个`Encrypted Handshake Message`, 将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。同样，服务器也可以发送`Change Cipher Spec`, 说:"没问题，咱们以后都采用协商的通信密钥和加密算法进行加密通信",并且也发送`Encrypted Handshake Message`的消息试试。当双方握手结束之后，就可以通过对称密钥进行加密传输。这个过程除了加密解密外，其他的过程和`HTTP`是一样的，过程也非常复制。

上面的过程只包含`HTTPS`的单向认证，也即客户端验证服务端的证书，是大部分的场景，也可以在更加严格安全要求的情况下，启用双向认证，双方互相验证证书。

### 重放与篡改
有了加密和解密, 黑客截获包也打不开，但它可以发送`N`次。这个往往通过`Timestamp`和`Nonce`随机数联合起来，然后做一个不可逆的签名来保证。`Nonce`随机数保证唯一，或者`Timestamp`和`Nonce`合起来保证唯一，同样的，请求只接收一次，于是服务器多次受到相同的`Timestamp`和`Nonce`, 则视为无效即可。如果有人想篡改`Timestamp`和`Nonce`, 还有签名保证不可篡改性，如果改了用签名算法解出来，就对不上了，可以丢弃。

## 流媒体协议
无论是直播还是点播，其实都是对于视频数据的传输。视频技术的三个名词系列：
* **名词系列一**： `AVI`, `MPEG`, `RMVB`, `MP4`, `MOV`, `FLV`, `WebM`, `WMV`, `ASF`, `MKV`。例如`RMVB`和`MP4`是不是很熟悉？
* **名词系列二**：`H.261`, `H.262`, `H.263`, `H.264`, `H.265`。这里重点关注 `H.264`。
* **名词系列三**：`MPEG-1`, `MPEG-2`, `MPEG-4`, `MPEG-7`, `MPEG`听说过，但是后面的数字是怎么回事?

视屏其实就是快速播放的一连串连续的图片。每一张图片，我们称为一**帧**。只要每秒钟帧的数据足够多，也即播放的足够快。比如每秒`30`帧，以人眼的敏感程度，是看不出这是一张张独立的图片的，这就是我们常说的**帧率**。每一张图片都是由像素组成的，假设为`1024x768`(这个像素不算多)。每个像素由`RGB`组成，每个`8`位，共`24`位。

我们来算一下，每秒钟的视频有多大？
> `30`帧 x `1024` x `768` x `24` = `566,231,040`(Bits) = `70,778,880`(Bytes)

> 如果是一分钟就是`4,246,732,800Bytes`, 已经是`4G`。这个数据量实在太大，根本没办法存储和传输。如果这样存储，硬盘很快就满了。这样传输，多少带宽也不够用。可以使用**编码**来用尽量上的`Bit`数保存视频，使播放时画面看起来仍然很精美。**编码是一个压缩的过程**。

**视屏和图片压缩过程中的特点**:
* **空间冗余**: 图像相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，没必要每个像素都完整的保存，可以隔几个保存一个，中间用算法计算出来。
* **时间冗余**: 视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有图片进行预测和推断。
* **视觉冗余**: 人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数据。
* **编码冗余**: 不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似**[霍夫曼编码](https://zh.wikipedia.org/wiki/%E9%9C%8D%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81)(Huffman Coding)**思路。

![视频压缩](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3783.JPG "视频压缩")

总之，用于编码的算法非常复杂，而且多种多样，但是编码过程其实都是类似的。

**视频编码两大流派**:
* **流派一**: `ITU`(International Telecommunications Union)的`VCEG`(Video Coding Experts Group), 这个称为**国际电联下的VCEG**。既然是电信，他们最初做视频编码，主要侧重传输。名词**系列二**，就是这个组织定的标准。
* **流派二**: `ISO`(International Standards Organization)的`MPEG`(Moving Picture Experts Group), 这个是**ISO旗下的MPEG**, 本来是做视频存储的。例如，编码后保存在`VCD`和`DVD`中。当然后来也慢慢侧重视频传输了。名词**系列三**就是这个组织制定的标准。

后来，`ITU-T`(国际电信联盟电信标准化部门，ITU Telecommunication Standardization Sector) 与 `MPEG`联合制定了`H.264/MPEG-4 AVC`,这才是我们这里关注的重点。进过编码之后，一帧帧的图像就变成一串串**二进制**,这个**二进制**可以放在一个文件里，按照一定的格式保存起来，这就是**名词系列一**。其实这些就是视频保存成文件的格式。例如，前几个字节是什么意义，后几个字节是什么意义，然后是数据，数据中保存的就是编码好的结果。

![直播流程](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3784_1.JPG "直播流程")

当然，这个**二进制**也可以通过某种网络协议进行封装，放在互联网上传输，这个时候就可以进行网络直播了。网络协议将**编码**好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的服务端来接收这些网络包，从而得到里面的视频流，这个过程称为**接流**。

服务端接到视频流之后，可以对视频流进行一定的处理，例如**转码**(从一个编码格式，转成另一种格式)。因为观众使用的客户端千差万别，要保证他们都能看到直播。**流处理**完毕之后，就可以等待观众的客户端来请求这些视频流。观众的客户端请求的过程称为**拉流**。

如果有非常多的观众，同时看一个视频直播，那都从一个服务器上**拉流**，压力太大，因而需要一个视频的**分发网络**，将视频预先加载到就近的边缘节点，这样大部分观众看的视频，是从边缘节点拉取的，就能降低服务器的压力。

当观众的客户端将视频流拉下来之后，就需要进行**解码**, 也即通过上述过程的逆过程，将一串串看不懂的二进制再转变成一帧帧生动的图片，在客户端**播放**出来。

接下来，我们依次看下每个过程：

![直播流程](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3785.JPG "直播流程")

* **编码：如何将丰富多彩的图片变成二进制流 **
> 虽然我们说视频是一张张图片的序列，但如果每张图片都完整，就太大了，因而会将视频序列分成**三种帧**:
* **I帧**: 也称关键帧。里面是完整的图片，只需要本帧数据，就可以完成解码
* **P帧**: 前向预测编码帧。`P帧`表示的是这一帧跟之前的一个关键帧(或`P帧`)的差别，解码时需要用之前缓存的画面，叠加上和本帧定义的差别，生成最终画面。
* **B帧**: 双向预测内插编码帧。`B帧`记录的是本帧与前后帧的差别。要解码`B帧`,不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的数据与本帧数据的叠加，取得最终的画面。

> 可以看出，`I帧`最完整，`B帧`压缩率最高，而压缩后帧的序列，应该在`IBBP`的间隔出现的。这就是**通过时序进行编码**。在一帧中，分成多个片，每个片中分成多个宏块，每个宏块分成多个子块，这样将一张大的图分解成一个个小块, 方便进行**空间上的编码**。, 

> 尽管时空非常立体的组成了一个序列，但是总归还是要压缩成一个二进制流。这个流是有结构的，是一个个**网络提取层单元(NALU, Network Abstraction Layer Unit)**。变成这种格式就是为了传输，因为网络上的传输，默认的是一个个的包，因而这里也就分成了一个个单元。

![NALU](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3786.JPG "NALU")

每个`NALU`首先是一个起始标识符，用于表示`NALU`之间的间隔；然后是`NALU`的头，里面主要配置`NALU`的类型；最终`Payload`里面是`NALU`承载的数据。在`NALU`头里，主要内的是容类型`NAL Type`:
* `0x07`表示`SPS`, 是序列参数集，包括一个图像序列的所有信息，如图像尺寸，视频格式等。
* `0x08`表示`PPS`, 是图像参数集，包括一个图像的所有分片的所有相关信息，包括图像类型，序列号等。

> 在传输视频流之前，必须要传输这两类参数，不然无法解码。为了保证容错性，每个`I帧`前面，都会传一遍这两个参数集合。**如果`NALU Header`里面的表示类型是`SPS`或`PPS`**, 则`Payload`中就是真正的参数集内容。**如果类型是帧**，则`Payload`中才是真的视频数据，当然也是一帧帧存放的，前面说了，一帧的内容还是挺多的，因而每一个`NALU`里保存的是一片。对于每一片，到底是`I帧`, 还是`P帧`,还是`B帧`,在片结构里也有个`Header`, 里面有个类型， 然后是片的内容。

> 这样，整个格式就出来了，**一个视频，可以拆分成一系列的帧，每帧拆分成一系列的片，每片都放在一个`NALU`里面，`NALU`之间都是通过特殊的起始标识符分隔，在每个`I帧`的第一篇前面，要插入单独保存`SPS`和`PPS`的`NALU`,最终形成一个长长的`NALU`序列**。

* **推流: 如何把数据流打包传输到对端**
这个格式还是不能直接在网上传输到对端的，还需要将这个二进制流打包成网络包进行发送，这里我们使用`RTMP协议`。这就进入第二个流程**推流**。`RTMP`是基于`TCP`的，因而肯定需要双方建议一个`TCP`连接。在有`TCP`连接的基础上，还需要建立一个`RTMP`连接，也即在程序里面，需要调用`RTMP`类库的`Connect`函数显示创建一个连接。

> `RTMP`为啥需要建立一个单独的连接？因为它们需要商量一些事情，保证以后传输能正常进行，主要就是两个事情:`1.`**版本号**，如果客户端服务器的版本号不一致，则不能工作。`2.`**时间戳**，视频播放中，时间是很重要的，后面的数据流互通时，经常要带上时间戳的差值，因而一开始双方就要知道对方的时间戳。 

未来沟通这些事情，需要发送六条消息；客户端发送`C0`,`C1`,`C2`, 服务器发送`S0`,`S1`,`S2`。首先客户端发送`C0`表示自己的版本号，不必等对方的回复，然后发送`C1`表示自己的时间戳。服务器只有在收到`C0`时，才能返回`S0`,表明自己的版本号，如果版本号不匹配，可以断开连接。服务器发送完`S0`后，也不用等什么，就直接发送自己的时间戳`S1`。客户端收到`S1`时，发一个知道对方时间戳的`ACK C2`。同理服务器收到`C1`时，发送一个知道对方时间戳的`ACK S2`。

![RTMP](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3787.JPG "RTMP")

握手之后，双方需要互相传递一些控制信息，例如`Chunk`块的大小，窗口大小等；真正传输时，还需要创建一个流`Stream`, 然后通过这个`Stream`来推流`publish`。**推流**的过程就是将`NALU`放在`Message`里面发送，这个也称为`RTMP Packet包`。`Message`的格式如下：

![Message](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3788_1.JPG "Message")

发送时去掉`NALU`起始标识符，因为这部分对于`RTMP`协议来说没有用。接下来，将`SPS`和`PPS`参数集封装成一个`RTMP`包发送，然后发送一个个片的`NALU`。`RTMP`在收发数据时并不是以`Message`为单位的，而是把`Message`拆分为`Chunk`发送，而且必须在一个`Chunk`发送完成之后，才能开始发送下一个`Chunk`.每个`Chunk`中都带有`Message ID`, 表示属于哪个`Message`, 接收端也会按照这个`ID`将`Chunk`组成`Message`。前面连接时，设置的`Chunk`块大小就是指这个`Chunk`，将大的消息变为小的块再发送，可以在低带宽的情况下，减少网络拥塞。如下是一个分块的例子:

> 假设一个视频的消息长度为`307`, 但是`Chunk`大小约定为`128`,于是会拆分为三个`Chunk`。第一个`Chunk`的`Type = 0`, 表示`Chunk`头是完整的；头里`Timestamp`为`1000`,总长度`Length`为`307`, 类型为`9`, 是个视频，`Stream ID`为`12346`, 正文部分承担`128`字节的`Data`。第二个`Chunk`也要发送`128`个字节，`Chunk`头由于和第一个`Chunk`一样，因此采用`Chunk Type = 3`,表示头一样就不再发送。第三个`Chunk`要发送的`Data`的长度为`307-128-128 = 51`个字节，还是采用`Type = 3`。

![Message](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3789_1.JPG "Message")

就这样数据就源源不断到达流媒体服务器，整个过程就像这样。

![Message](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3790.JPG "Message")

这时，大量观看直播的观众就可以通过`RTMP`协议从流媒体服务器上拉取，但这么多的用户量，都去同一个地方拉取，服务器压力会很大，而且用户分布在全国甚至全球，如果都去统一的一个地方下载，也会时延比较长，需要有分发网络。分发网络分为**中心**和**边缘**两层。边缘层服务器部署在全国各地及横跨各大运营商里，和用户距离很近。中心层是流媒体服务集群，负责内容的转发。智能负载均衡系统，根据用户的地理位置信息，就近选择边缘服务器，为用户提供 **推/拉** 流服务。中心层也负责转码服务，例如，把`RMTP`协议的码流转换为`HLS`码流。

![Message](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3791.JPG "Message")

这套机制在后面的`DNS`, `HTTPDNS`, `CDN`会详细描述。

* **拉流: 观众的客户端如何看视频**

![Message](http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3792.JPG "Message")

先读到的是`H.264`的解码参数，例如`SPS`和`PPS`，然后对收到的`NALU`组成一个个帧，进行解码，交给播放器播放，一个绚丽多彩的视频画面就出来了。

## DNS 协议
`DNS`服务器一定要设置成高可用，高并发和分布式的。树状层级结构：
* 根`DNS`服务器: 返回顶级域 `DNS` 服务器的 `IP` 地址
* 顶级域`DNS`服务器: 返回权威`DNS` 服务器的 `IP` 地址
* 权威`DNS`服务器: 返回相应主机的`IP`地址

为了提高`DNS`解析性能， 很多网络多会就近部署`DNS`缓存服务器。`DNS`的解析流程如下：
* 电脑客户端发送一个`DNS`请求，问 [http://www.163.com](http://www.163.com) 的 `IP` 是啥？并发给本地域名服务器(本地`DNS`: 如果通过`DHCP`配置，本地`DNS`由网络服务商`ISP`,如电信，移动等自动分配，通常在网络服务商的某个机房)
* 本地`DNS`收到来自客户端的请求。这台服务器上缓存一张域名与与之对应`IP地址`的大表格, 如果能找到，直接返回`IP地址`. 如果没有，本地`DNS`会去根域名服务器找， 根域名服务器是最高层次， 全球共有`13`套。它不直接用于域名解析，但能知名一条道路。
* 根`DNS`收到来自本地`DNS`的请求，发现后缀是`.com`, 发现是由`.com`区域管理， 获得顶级域名服务器地址
* 本地`DNS`转向问顶级域名服务器，顶级域名服务器就是比如`.com`, `.net`, `.org` 这些一级域名，它负责管理二级域名， 比如`163.com`。
* 从顶级域名服务器获取[http://www.163.com](http://www.163.com)区域的权威`DNS`服务器地址
* 本地`DNS`转向权威`DNS`服务器，`163.com` 的权威`DNS`服务器是域名解析结果的源出处
* 权威`DNS`服务器查询后将相应的`IP地址` `X.X.X.X`告诉本地`DNS`.
* 本地`DNS`再将`IP地址`返回客户端，客户端和目标建立连接.

### 负载均衡
站在客户端的角度， 上面的过程是一次`DNS递归查询过程`。这个过程中，`DNS` 除了可以通过名称映射为`IP地址`，还可以实现**负载均衡**.

`DNS`首先可以做**内部负载均衡** , 还可以实现**全局负载均衡**。

> **DNS访问数据中心中对象存储上的静态资源**：假设全国有多个数据中心，托管在多个运营商， 每个数据中心有三个可用区(`Available Zone`)。对象存储通过跨可用区部署，实现高可用性。 在每个数据中心中， 都至少部署两个内部负载均衡器，内部负载均衡器后面对接多个对象存储的前置服务器。
* 当一个客户端要访问`object.yourcompany.com`时，需要将域名转换为`IP地址`进行访问，所以要请求`本地DNS解析器`
* `本地DNS解析器`先查看本地的缓存是否有这个记录。如果有直接使用
* 如果本地无缓存，则需要请求`本地DNS服务器`
* `本地DNS服务器`一般部署在你的数据中心或者你所在运营商的网络中，`本地DNS服务器`也需要看本地是否有缓存， 如果有则返回 
* 如果本地没有，`本地DNS` 才需要递归从`根DNS服务器`查到`.com`的顶级域名服务器，最终查到`yourcompany.com`的`权威DNS服务器`给`本地DNS服务器`，`权威DNS服务器`会返回真实要访问的`IP地址`

