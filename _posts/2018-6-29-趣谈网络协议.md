---
layout: post
title: "趣谈网络协议"
description: "网络"
category: NetWork
tags: [Life]
---

{% include JB/setup %}


--------------------------


# 趣谈网络协议
**应用层**: `DNS`, `Http`, `Https` 所在的层为应用层.

**传输层**: 应用层封装成包之后会交给传输层（通过`Socket`编程来实现), `传输层`有两种协议：
* 无连接的`UDP`协议
* 面向连接的`TCP`协议
    * `TCP` 协议里有两个端口:
        * 浏览器监听的端口
        * 服务器监听的端口

> 操作系统往往通过端口来判断得到的包应该给哪个进程。

**网络层**: 网络层的协议是IP协议, 会有源`IP`地址和目标`IP`地址。
> 操作系统启动的时候会被 `DHCP` 协议配置`IP`地址, 以及默认网关的IP地址*(192.168.1.1)*.

**MAC层**: 操作系统通过 `ARP` 协议将`IP`地址发送给网关, 将 `IP`包交给下一层 `Mac层`.

* 网关往往是一个路由器, 路由器上维护一张路由表, 路由表由    相邻的路由器通过路由协议得到(常用的有 `OSPF` 和 `BGP`). 最后一个路由器知道这个网络包要去的地方，目标服务器会回复一个 `Mac地址`,  通过这个 `Mac地址`就可以找到目标服务器.

* 目标服务器发现 `Mac地址` 对上， 取下 `Mac头` 发送给操作系统`网络层`, 发现 `IP` 也对上, 取下`IP头`交给`传输层(TCP层)`，传输层对于收到的每个包，都会回复一个包说明收到。如果过一段时间还没到，发送端的`TCP层`会重新发送这个包。

* 当网络包平安到达 `TCP层` 之后, `TCP头`中有目标端口号. 通过 `RPC调用`(`RPC`框架有很多种，有基于`HTTP协议`的放在`HTTP`报文里的，有直接封装在`TCP`报文里的) 来告诉监听这个端口的服务器进程。

## ifconfig 命令
`Windows`上通过`ipconfig`, `Linux`上通过`ifconfig`命令或者`ip addr`命令 `来查看`IP`地址.
> `IP`地址是一个网卡在网络世界的通讯地址，相当于我们现实世界的门牌号。

## 无类型域间选路(CIDR)
将`32`位的`IP`地址分为网络考和主机好两部分。类似于 `10.100.122.2/24`, 前`24`位表示网络号，后`8`位表示主机号.

## 公有IP地址和私有IP地址

![Ip分类]( http://7xpgi9.com1.z0.glb.clouddn.com/IPRange.png "IP分类")

> 公有`IP`地址有个组织统一分配。`192.168.0.x`是最常用的私有`IP`地址.`192.168.0.1`往往就是私有网络的出口地址，例如：家里的电脑连接 `Wi-Fi`, `Wi-Fi` 路由器的地址就是 `192.168.0.1`. `192.168.0.255` 是广播地址, 一旦发送这个地址， 整个`192.168.0`网络里的所有机器都能收到。

## ICMP与ping
`ping` 是基于`ICMP`(`Internet Control Message Protocol`, 互联网控制报文协议)协议工作的. `ICMP` 报文封装在 `IP` 包里面, 有很多的类型，不同类型有不同的代码。最常用的类型是主动请求为`8`, 主动请求的应答为`0`. 常用的`ping`就是查询报文，是一种主动请求，并且获得主动应答的`ICMP`协议.

对`ping`的主动请求，进行抓包称为 `ICMP ECHO REQUEST`.同理主动请求的回复，称为`ICMP ECHO REPLY`.比起原生的`ICMP`, 这里多了两个字段:
* 标识符
* 序号

### ICMP差错报文类型
* 终点不可达`3`, 具体的原因在代码中的标示
    * 网络不可达代码为`0`
    * 主机不可达代码为`1`
    * 协议不可达代码为`2`
    * 端口不可达代码为`3`
    * 需要进行分片但设置了不分片位代码为`4`
* 源抑制`4`
* 超时`11`
* 重定向`5`

### ping: 查询报文类型的使用
`主机A` 的`IP`地址是`192.168.1.1`, `主机B`的`IP`地址是`192.168.1.2`, 在同一子网， `主机A` 运行 `ping 192.168.1.2` 发生了啥？

> 源主机首先会构建一个`ICMP`请求数据包，`ICMP`数据包包含多个字段。最重要的以下两个：
* 类型字段: 对于请求数据包而言该字段为`8`
* 顺序号: 主要用于区分连续`ping`时发出的多个数据包,每发出一个请求数据包，顺序号会自动`+1`.

> 为了能计算往返时间`RTT`, 会在报文的数据部分插入发送时间。然后，由`ICMP`协议将数据包连同地址`192.168.1.2`一同交给`IP层`。`IP层`以`192.168.1.2`作为目的地址，本机`IP地址`作为源地址，加上一些其他控制信息，构建一个`IP数据包`。

### MAC头和IP头的细节
`MAC头`: 里先是`目标MAC地址`，然后是`源MAC地址`和一个协议类型。用来说明里面是`IP`协议。
`IP头`: 里面的版本号， 目前主流的是`IPv4`, 服务类型`TOS`,`TTL`和`8`标识协议.

任何一台机器上，当要访问另一个`IP地址`的时候，都会先判断，这个`目标IP地址`和当前机器的`IP地址`是否在同一网段，需要使用`CIDR`和子网掩码。
* 同一网段：直接将源地址和目标地址放入`IP头`中，然后通过`ARP`获得`MAC地址`，将`源MAC`和`目的MAC`放入`MAC头`中发出去。
* 不同网段: 需要发往默认网关`Gateway`, `Gateway`地址一定和`源IP地址`在同一网段。网关往往是一个路由器，是一个三层转发设备。但是把网关叫做路由器是不完全准确的 `路由器是一台设备，它有五个网口或网卡，相当于有五只手，分别连着五个局域网。每只手的IP地址都和局域网的IP地址在相同的网段，每只手都是它握住哪个局域网的网关`

## UDP 协议
`TCP`是面向连接的， `UDP`是面向无连接的。在互通之前，面向连接的协议会先建立连接，例如：`TCP`会三次握手，而`UDP`不会。

**所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。**
* **`TCP`提供可靠交付**。通过`TCP`连接传输的数据，无差错，不丢失，不重复，并且按序到达。 **`UDP`继承了`IP包`的特性，不保证不丢失，不保证按顺序到达。**
* **`TCP`是面向字节流的**。发送的时候发的是一个流，没头没尾。`IP包`不是一个流，而是一个个`IP包`。之所以变成流，是`TCP`自己状态维护做的事情。**`UDP`继承了`IP`的特性，基于数据报的, 一个个的发，一个个的收。**
* **`TCP`可以有拥塞控制的**。它意识到包丢弃了或者网络环境不好，会根据清空调整自己的行为，看看是不是发快了， 要不要发慢点。 **UDP就不会，应用让我发，我就发。**
* **`TCP`其实是一个有状态服务**， **而`UDP`则是无状态服务**

### UDP包头
当我们发送的`UDP`包到达目标机器后，发现`MAC地址`匹配，于是取下来，将剩下的包传给处理`IP层`的代码。把`IP头`取消来，里面有个`8位`协议，会标示出数据到底是`TCP`还是`UDP`。

无论是`TCP`传数据还是`UDP`传数据，都要监听一个端口。`TCP` 还是 `UDP` 包头里有个端口号， 根据端口号，将数据交给相应的应用程序。

### UDP三大特点 
* **沟通简单**：不需要大量的数据结构，处理逻辑，包头字段。
* **轻信他人**：不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，它也可以传给任何人数据，甚至可以同时传给多人数据。
* **做事不懂权变**：不会根据网络的情况进行发包的拥塞控制，无论网络丢包成啥样，还是该怎么发就怎么发。

### UDP三大使用场景 
* **需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用**
* **不需要一对一沟通，建立连接，而是可以广播的应用**
* **需要处理速度快，时延低， 可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前**

### UDP的五个例子
* **网页或者`App`的访问**: `QUIC`(Quick UDP Internet Connections，快速`UDP`互联网连接啊)是`Google`提出的一种基于`UDP`改进的通信协议，目的是降低网络通信延迟，提供更好的用户互动体验。`QUIC`在应用层上，会自己实现快速连接建立，减少重传时延，自适应拥塞控制。
* **流媒体协议**: 直播协议多使用`RTMP`(也是基于`TCP`的), 由于`TCP`的限制，很多直播应用都基于`UDP`实现自己的视频传输协议。
* **实时游戏**: 要求较为严格，采用自定义的可靠`UDP`协议，自定义重传策略， 能够把丢包产生的延迟降到最低，尽量减少网路问题对游戏性造成的影响。
* **IoT物联网**：一方面物联网领域终端资源少，很可能只是个内存非常小的嵌入式系统，而维护`TCP协议`代价太大；另一方面，物联网对实时性要求也很高，`Google`旗下的`Nest`建立`Thread Group`，推出了物联网通信协议 `Thread` , 就是基于`UDP协议的`
* **移动通行领域**: 在`4G`网络里，移动流量上网的数据面对的协议`GTP-U`是基于`UDP`的。因为移动网络协议比较复杂，而`GTP协议`本身就包含复杂的手机上线下线的通信协议。如果基于`TCP`, `TCP`的机制就显得非常多余。

## TCP 协议
### TCP包头格式 
* **源端口号**和**目标端口号**是不可少的，这一点和`UDP`一样。如果没有这两个端口号，数据就不知道应该发给哪个应用。
* **包的序列号**为了解决乱序的问题。
* **确认序号**发出去的包应该有确认，如果没有收到就应该重新发送，直到送达。这个可以解决不丢包的问题。
> `TCP`是可靠的协议，对于`TCP`来讲，`IP层`丢不丢包我管不着，我自己会通过不断重传保证可靠性。

* **状态位**: `SYN`是发起一个连接，`ACK`是回复, `RST`是重新连接, `FIN`是结束连接。`TCP`是面向连接的，双方要维护连接的状态，这些带状态位的包发送，会引起双方的状态变更。
* **窗口大小**: `TCP`要做**流量控制**，通信双方各申明一个窗口，标示自己当前的处理能力，别发送太快，也别发送太慢。
* **拥塞控制**：对于真正的通路堵不堵车，它无能为力，唯一能做的就是控制自己(控制发送的速度)

`TCP`协议需要重点关注以下几个问题：
 * 顺序问题，稳重不乱
 * 丢包问题，承诺靠谱
 * 连接维护，有始有终
 * 流量控制，把握分寸
 * 拥塞控制，知进退
 
### TCP三次握手
我们假设通路非常不靠谱，`A`要发起一个连接，当发了第一个请求了无音讯的时候，会有很多可能性，比如**第一个请求包丢了**, **超时了**还是**`B`没有响应，不想和我连接**。

`A`不能确认结果，于是再发。终于，又一个请求包到了`B`, 但是请求包到了`B`这个事情，`A`是不知道的，`A`还有可能再发。

`B`收到请求包，就知道`A`的存在，并且知道`A`要和它建立连接。如果`B`不乐意建立连接，则`A`会重试一段时间后放弃，连接建立失败，没有问题；如果`B`乐意建立连接，则会发送应答包给`A`。

对于`B`来说，这个应答包也是不知道能不能到达`A`。这个时候`B`自然不能认为连接建立好了，因为应答包仍然会丢，会绕弯路，或者`A`已经挂了。这个时候`B`还碰到一个诡异的现象，`A`和`B`原来建立连接，做了简单通信后，结束连接。`A`建立连接时，请求包重复发了几次，有的请求包绕了一大圈又回来，`B`会认为这是一个正常的请求，因此建立连接，可以想象这个连接不会进行下去，也没有终止的时候。

`B`发送的应答可能会发送多次，但只要一次到达`A`, `A`就认为连接已经建立，因为对于`A` 来说，他的消息有去有回，`A`会给`B`应答的应答，只有当`B`等到这个消息才会建立连接。
> 三次握手除了双方建立连接外，主要为了沟通**`TCP包`的序号问题**。每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个`32`位的计数器，每`4ms`加一。

### TCP 四次挥手
`A`开始说"不玩了"，`B`说"知道了"。这个是没有什么问题的，因为在此之前，双方还处于合作状态，如果`A`说"不玩了"，没有收到回复，就会重新发送。但是这个会和结束之后，就可能有异常情况：
* `A`说完"不玩了"之后，直接跑路，就会有问题，`B`还没有发起结束，也得不到回答，`B`就不知道怎么办
* `A`说完"不玩了"，`B`直接跑路，也是有问题的，因为`A`不知道`B`是还是事情要处理，还是过一会儿会发送结束。

> `TCP` 专门设计几种状态来处理这些问题:
* 断开的时候, 当`A`说"不玩了"，就进入`FIN_WAIT_1`的状态，`B`收到`A不玩了`的消息后，发送知道了就进入`CLOSE_WAIT`的状态
* `A`收到`B说知道了`，就进入`FIN_WAIT_2`状态，如果这个时候`B`直接跑路，则`A`将永远在这个状态。`TCP`协议里没有对这个状态的处理，但是`Linux`有，可以调整`tcp_fin_timeout`这个参数， 设置一个超时时间。
* `B`没有跑路，发送了`B也不玩了`的请求到达`A`时，`A`发送"知道B也不玩了"的`ACK`后，从`FIN_WAIT_2`状态结束，按说`A`可以跑路了，但是这个最后的`ACK`万一`B`收不到呢? 则`B`会重新发一个`B不玩了`，这个时候`A`已经跑路了的话，`B`就再也收不到`ACK`了， 因而`TCP协议`要求`A`最后等待一段时间`TIME_WAIT`, 这个时间要足够长，长到如果`B`没有收到`ACK`的话，"B 说不玩了"会重发，`A`会重新发一个`ACK`并且足够时间到达`B`。
* `A` 直接跑路还有一个问题，`A`的端口直接空出来了，但是`B`不知道，`B`发送过来的恶很多包很可能还在路上，如果`A`的端口被一个新的应用占用，这个新的应用就会收到上个连接中`B`发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而需要等足够长的时间，等到原来`B`发送的所有包都死翘翘，再空出端口来。等待时间设为`2MSL`(MSL是Maximum Segment Lifetime, 报文最大生存时间)
* 还有个异常就是`B`超过`2MSL`后，依然没有收到它发的`FIN`的`ACK`, 按照`TCP`的原理，`B`当然会重发`FIN`, 这个时候`A`再收到这个包之后，`A`就直接发送`RST`, `B`就知道`A`早跑了。

### 如何实现靠谱的协议
`TCP协议`为了保证顺序性，每一个包都有一个`ID`。在建立连接的时候，会商定起始的`ID`是什么，然后按照`ID`一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个个来的，而是会应答某个之前的`ID`, 表示都收到了, 这种模式称为**累计确认或累计应答**(`cumulative acknowledgment`)。为了记录所有发送和接收的包，`TCP`也需要发送和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的`ID`一个个排列，根据处理情况分成`4`个部分：
* 发送并且已经确认的。这部分表示处理完的，应该划掉。
* 发送并尚未确认的。还没有处理完的，需要等待处理完回复之后，才能划掉。
* 没有发送，但是已经等待发送，这部分还没有交代给下属，但是马上要交代的。
* 没有发送，并且暂时也不会发送。这部分表示还没有交代下属，而且暂时也不会交代给下属。
> 第`3`点和第`4`点做区分是为了**流量控制，把握分寸**。在`TCP`里，接收端会给发送端报一个窗口大小(`Advertised Window`), 这个窗口的大小应该等于第`2`点和第`3`点的总和，超过这个窗口，接收端处理不过来就不能发送。

于是发送端需要保持下面的数据结构:
* `LastByteAcked`: 第`1`点和第`2`点的分界线
* `LastByteSent`: 第`2`点和第`3`点的分界线
* `LastByteSend + AdvertisedWindow`: 第`3`点和第`4`点的分界线

对于接收端来说，它的缓存里记录的内容要简单一些：
* **接收并确认过的**: 就是交代给我，并且我做完的。
* **还没接收,但是马上就能接收的**: 就是我自己能够接收的最大工作量
* **还没接收，也没法接收的**: 超出工作量的部分，实在做不完。

> 对应的数据结构就是:
* `MaxRcvBuffer`: 最大缓存的量
* `LastByteRead`: 之后是已经接收了，但还没有被应用层读取的。
* `NextByteExpected`: 第`1`部分和第`2`部分的分界线。

## Socket套接字
`Socket`编程进行端到端通信，往往意识不到中间经过多少局域网，多少路由器，因而能够设置的参数，也只能是端到端协议之上网络层和传输层。
> 在网络层，`Socket`函数需要指定到底是`IPv4`还是`IPv6`, 分别对应设置为`AF_INET`和`AF_INET6`。另外，还要指定到底是`TCP`(**基于数据流*，设置为`SOCK_STREAM`)还是`UDP`(**基于数据报**,设置为`SOCK_DGRAM`)。

### 基于TCP协议的Socket程序函数调用过程
两端创建`Socket`之后, `TCP`服务端先监听一个端口，一般先调用`bind函数`, 给这个`Socket`赋一个`IP`和`端口`。原因如下:
* `IP`: 一台机器可能会有多个网卡，也就有多个`IP`地址,可以选择监听所有的网卡，也可以选择监听一个，只有发给这个网卡的包才会给你。
* `端口`: 一个网络包来的时候，内核要通过`TCP头`里的这个端口，来找到你这个应用程序，把包给你。

当服务器有`IP`和`端口号`, 就可以调用`listen`函数进行监听。在`TCP`的状态图里，有个`listen`状态，当调用这个函数之后， 服务器就进入这个状态， 客户端就可以发起连接。

内核中为每个`Socket`维护两个队列：
* 已经建立连接的队列， 这时连接三次握手已经完毕，处于`established`状态
* 还没有完全建立连接的队列，这时三次握手还没有完成，处于`syn_rcvd`状态

接下来，服务端调用`accept`函数，拿出一个已完成的连接进行处理，如还没完成就要等着。在服务端等待的时候，客户端可以通过`connect`函数发起连接，先在参数中指明要连接的`IP地址`和`端口号`， 然后开始发起三次握手，内核会给客户端分配一个临时的端口。一旦握手成功，服务端的`accept`就会返回另一个`Socket`。监听的`Socket`和真正用来传数据的`Socket`是两个，一个叫做**监听Socket**, 一个叫做**已连接Socket**。连接建立成功之后，双方开始通过`read`和`write`函数来读写数据，就像往一个文件流里写东西一样。

<img src="http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3776.JPG" width=500>

在内核中`Socket`是一个文件，对应就有文件描述符。每个进程都有一个数据结构`task_struct`，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是个整数，是这个数组的下标。这个数组中的内容是一个指针，指向内核中所有打开的文件列表。既然是一个文件，就会有一个`inode`, 只不过`Socket`对应的`inode`不像真正的文件系统一样，保存在硬盘上，而是在内存中。这个`inode`指向`Socket`在内核中的`Socket`的结构。

这个结构里，主要是两个队列，1.**发送队列** 2.**接收队列**。在这两个队列里保存的是一个缓存`sk_buff`。这个缓存里能够看到完整的包结构。

### 基于UDP协议的Socket程序函数调用过程
`UDP`是没有连接的，不需要三次握手，也就不需要调用`listen`和`connect`, 但`UDP`交互仍需要`IP`和`端口号`就需要`bind`。`UDP`是没有维护连接状态的，因而不需要每对连接建立一组`Socket`, 而是只要有一个`Socket`就能和多个客户端通信。也正是因为没有连接状态，每次通信时，都调用`sendto`和`recvfrom`, 都可以传入`IP地址`和端口。

### 服务器如何连接更多项目
**最大连接数**, 系统会用一个四元祖来标识一个`TCP`连接。
> {本机IP, 本机端口，对端IP, 对端端口}

服务器通常固定在某个本地端口上监听，等待客户端的连接请求。因此，服务端`TCP`连接四元祖中只有`对端IP`（客户端`IP`）和 `对端端口`(客户端端口)是可变的。因此:
> 最大`TCP`连接数 = 客户端`IP`数 x 客户端端口数

> 对于`IPv4`，客户端`IP`数最多为`2^32`, 客户端端口数最多为`2^16`, 也就是服务端单机最大`TCP`连接数，约为 `2^48`。

当然，服务端最大并发`TCP`连接数远不能达到理论上限。首先主要是**文件描述符限制**, 按照上面的原理，`Socket`都是文件，所以首先要通过`ulimit`配置文件描述符数目；另一个限制是**内存**, 按照上面的数据结构，每个`TCP`连接都要占用一定内存，操作系统内存是有限的。

可以通过以下方式来降低每个项目消耗的资源数目：

<img src="http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3773.JPG" width=500>

* **将项目外包给其他公司(多进程方式)**: 一旦建立一个连接，就会有个已连接`Socket`, 这时可以创建一个子进程，然后将基于已连接`Socket`的交互交给这个新的子进程来做。在`Linux`下，创建子进程使用`fork`函数（在父进程的基础上完全拷贝一个子进程）。在`Linux`内核中，会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到哪行程序的进程。显然, 复制的时候调用`fork`, 复制完毕之后，父进程和子进程都会记录当前刚刚执行完`fork`。这两个进程刚复制完的时候，几乎一摸一样，只是根据`fork`的返回值来区分到底是父进程(返回其他整数)，还是子进程(返回`0`)。因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为`accept`创建的已连接`Socket`也是一个文件描述符，同样会被子进程获得。 接下来, 子进程可以通过这个已连接`Socket`和客户端进行互通了，当通信完毕之后，就可以退出进程。（`fork`时返回整数就是父进程，这个整数就是子进程的`ID`, 父进程可通过这个`ID`查看子进程是否完成项目，是否需要退出）

<img src="http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3774.JPG" width=500>

* **将项目转包给独立的项目组(多线程方式)**: 相比`进程`来说，创建`线程`就相当于在同一个公司成立项目组。一个项目做完了，那这个项目组就可以解散，组成另外的项目组，办公家具都可公用。在`Linux`下，通过`pthread_create`创建一个线程，也是调用`do_fork`。 不同的是，虽然新的线程在`task`列表会新创建一项，但是很多资源，例如**文件描述符列表**，**进程空间**，还是共享的，只不过多了一个应用而已。新的线程也可以通过已连接`Socket`处理请求，从而达到并发处理的目的。

> 上面基于进程或线程模型，其实还是有问题的。新到来一个`TCP`连接，就需要分配一个进程或线程。一台机器无法创建很多进程或线程。有个`C10K`(**一台机器要维护`1万`个连接，就要创建`1万`个进程或线程，操作系统是无法承受的**)。

* **一个项目组支撑多个项目(IO多路复用，一个线程维护多个Socket)**: 由于`Socket`是文件描述符，因而某个线程盯的所有`Socket`,都放在一个文件描述符集合`fd_set`中，这就是**项目进度墙**，然后调用`select`函数来监听文件描述符集合是否有变化。一旦变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在`fd_set`对应的位都设为`1`，表示`Socket`可读可写，从而可以进行读写操作，然后调用`select`进行下一轮。

<img src="http://7xpgi9.com1.z0.glb.clouddn.com/IMG_3775.JPG" width=500>

* **一个项目组支撑多个项目(IO多路复用，从"派人盯着"到"有事通知")**: 上面`select`函数还是有问题，因为每次`Socket`所在地恶文件描述符集合中`Socket`发生变化时，都需要通过轮询的方式来查看进度，这大大影响了一个项目组能支撑的最大项目数量。因而使用`select`, 能够同时盯的项目数量由`FD_SETSIZE`限制。如果改成事件通知的方式，情况就会好很多，项目组不需要通过轮询挨个盯着这些项目，而是当项目进度发生变化时，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。能完成这件事的函数叫`epoll`, 它在内核中的实现不是通过轮询的方式，而是通过注册`callback函数`的方式，当某个文件描述符发送变化时，就会主动通知。如图所示，假设进程打开了`Socket` `m n x`等多个文件描述符，现在需要通过`epoll`来监听是否这些`Socket`都有事件发生。其中`epoll_create`创建一个`epoll对象`，也是一个文件，也对应一个文件描述符，同样对应着打开文件列表中的一项。在这项里有一个红黑树，在红黑树里，要保存这个`epoll`要监听所有`Socket`。当`epoll_ctl`添加一个`Socket`时，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的`Socket`事件列表中。到一个`Socket`来了一个事件时，可以从这个列表中得到`epoll对象`,并调用`callback`通知它。这种通知方式使得监听的`Socket`数据增加的时候，效率不会大幅度降低，能够同时监听的`Socket`的数目也非常多。上限为系统定义的，进程打开的最大文件描述符个数。因而，**epoll被称为解决`C10K`问题的利器**。

## HTTP协议
登陆 [www.163.com](http://www.163.com) 这个 `URL`(同一资源定位符), 浏览器会将 [www.163.com](http://www.163.com) 这个域名发送给 `DNS服务器`, 让他解析`IP地址`. `HTTP` 先通过三次握手建立 `TCP连接`. (目前使用的`HTTP协议`大部分都是`1.1`, 是默认开启 `Keep-Alive`, 建立的`TCP`连接，可以在多次请求中复用)。

`HTTP`的报文可以分为`3`大部分
* 请求行
请求行中`URL`就是[www.163.com](http://www.163.com)，版本为`HTTP 1.1`, **方法**有几种类型:
    * 访问网页来说，最常用的就是`GET`，服务器决定放回什么格式的内容(`JSON`字符串等)。
    * `POST` 需要主动告诉服务器一些信息。一般会放在正文里。正文可以用各种各样的格式。常见的格式也是`JSON`.
    * `PUT` 向指定资源位置上传最新内容. 但是，`HTTP`服务器往往不允许上传文件， 所以 `PUT` 和 `POST` 都变成要穿东西给服务器的方法。实际使用过程中， `POST` 往往用来创建一个资源，`PUT` 用来修改资源。
    * `DELETE` 用来删除资源。

* 首部
首部都是 `key` `value` 格式，通过冒号分隔。 里面保存一些非常重要的字段。例如:
    * `Accept-Charset` 表示客户端可以接收的字符集, 防止产生乱码。
    * `Content-Type` 表示正文的格式，我们使用 `POST` 请求， 如果正文是`JSON`这个值设置为`JSON`.
    * `Cache-control` 用来控制缓存
    * `If-Modified-Since`
* 正文实体

> `HTTP`请求发送: `HTTP协议` 是基于`TCP协议`的， 使用面向连接的方式发送请求， 通过 `stream` 二进制流的方式传给对方， 到了`TCP层`, 会把二进制流变成一个个报文段发送给服务器.

### HTTP返回的构建
`HTTP` 返回报文也有一定格式， 也是基于`HTTP 1.1`.
* 状态行
    * 状态码： 会反应`HTTP`请求的结果. `200`意味一切顺利; `404` 表示服务器无法响应这个请求。
    * 短语: 会大概说明一下原因。
* 首部
    * `Retry-After`表示告诉客户端应该在多长时间之后再尝试。`503`错误表示**服务器暂时不再和这个值配合使用**。
    * `Content-Type` 表示返回的是`HTML` 还是 `JSON`.

> `HTTP 1.1` 在应用层以纯文本的形式进行通信。 每次通信都要带完整的`HTTP头`, 不考虑`pipeline模式`的话， 每次的过程总是一来一回， 在**实时性**, **并发性**上都存在问题。 `HTTP 2.0` 会对 `HTTP头`进行一定的压缩， 将原来每次都要携带得的大量的 `key value` 在两端建立一个索引表, 对相同的头只发送索引表中的索引。

`Google` 的 `QUIC协议`, 从 `TCP` 切换到 `UDP`, 有如下几个特点:
* 自定义连接机制
> 不再以四元组(`源IP`,`源端口`,`目的IP`,`目的端口`)标识，而是以一个`64位`随机数作为`ID`来标识，而且`UDP`是无连接的，所以`IP`或`端口`变化时, 只要`ID`不变， 就不需要重新建立连接.

* 自定义重传机制
> `TCP` 为了保证可靠性，通过使用**序号**和**应答**机制类解决顺序和丢包问题。`QUIC`定义来一个`offset`的概念。`QUIC`是面向连接的，就像`TCP`一样是一个数据流, 发送的数据在这个数据流里有个偏移量`offset`, 可以通过 `offset` 查看数据发送到哪里， 只要`offset`包没有来就要重发。

* 无阻塞多路复用
> 有了自定义的连接和重传机制就可以解决`HTTP 2.0`的多路复用问题。

* 自定义流量控制
> `TCP`通过**滑动窗口协议**来实现流量控制。`QUIC`也通过`window_update`, 但是是适应自己的多路复用机制的， 不但在一个连接上控制窗口， 还在一个连接中的每个`steam`控制窗口。

## DNS 协议
`DNS`服务器一定要设置成高可用，高并发和分布式的。树状层级结构：
* 根`DNS`服务器: 返回顶级域 `DNS` 服务器的 `IP` 地址
* 顶级域`DNS`服务器: 返回权威`DNS` 服务器的 `IP` 地址
* 权威`DNS`服务器: 返回相应主机的`IP`地址

为了提高`DNS`解析性能， 很多网络多会就近部署`DNS`缓存服务器。`DNS`的解析流程如下：
* 电脑客户端发送一个`DNS`请求，问 [http://www.163.com](http://www.163.com) 的 `IP` 是啥？并发给本地域名服务器(本地`DNS`: 如果通过`DHCP`配置，本地`DNS`由网络服务商`ISP`,如电信，移动等自动分配，通常在网络服务商的某个机房)
* 本地`DNS`收到来自客户端的请求。这台服务器上缓存一张域名与与之对应`IP地址`的大表格, 如果能找到，直接返回`IP地址`. 如果没有，本地`DNS`会去根域名服务器找， 根域名服务器是最高层次， 全球共有`13`套。它不直接用于域名解析，但能知名一条道路。
* 根`DNS`收到来自本地`DNS`的请求，发现后缀是`.com`, 发现是由`.com`区域管理， 获得顶级域名服务器地址
* 本地`DNS`转向问顶级域名服务器，顶级域名服务器就是比如`.com`, `.net`, `.org` 这些一级域名，它负责管理二级域名， 比如`163.com`。
* 从顶级域名服务器获取[http://www.163.com](http://www.163.com)区域的权威`DNS`服务器地址
* 本地`DNS`转向权威`DNS`服务器，`163.com` 的权威`DNS`服务器是域名解析结果的源出处
* 权威`DNS`服务器查询后将相应的`IP地址` `X.X.X.X`告诉本地`DNS`.
* 本地`DNS`再将`IP地址`返回客户端，客户端和目标建立连接.

### 负载均衡
站在客户端的角度， 上面的过程是一次`DNS递归查询过程`。这个过程中，`DNS` 除了可以通过名称映射为`IP地址`，还可以实现**负载均衡**.

`DNS`首先可以做**内部负载均衡** , 还可以实现**全局负载均衡**。

> **DNS访问数据中心中对象存储上的静态资源**：假设全国有多个数据中心，托管在多个运营商， 每个数据中心有三个可用区(`Available Zone`)。对象存储通过跨可用区部署，实现高可用性。 在每个数据中心中， 都至少部署两个内部负载均衡器，内部负载均衡器后面对接多个对象存储的前置服务器。
* 当一个客户端要访问`object.yourcompany.com`时，需要将域名转换为`IP地址`进行访问，所以要请求`本地DNS解析器`
* `本地DNS解析器`先查看本地的缓存是否有这个记录。如果有直接使用
* 如果本地无缓存，则需要请求`本地DNS服务器`
* `本地DNS服务器`一般部署在你的数据中心或者你所在运营商的网络中，`本地DNS服务器`也需要看本地是否有缓存， 如果有则返回 
* 如果本地没有，`本地DNS` 才需要递归从`根DNS服务器`查到`.com`的顶级域名服务器，最终查到`yourcompany.com`的`权威DNS服务器`给`本地DNS服务器`，`权威DNS服务器`会返回真实要访问的`IP地址`

